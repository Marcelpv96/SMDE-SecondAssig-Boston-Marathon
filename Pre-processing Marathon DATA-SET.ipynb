{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing boston marathon Data-set\n",
    "\n",
    "The aim of this is to process the three results available of boston marathon here:\n",
    "\n",
    "    - https://www.kaggle.com/rojour/boston-results\n",
    "    \n",
    "With the objective of split our information in this couple of segments:\n",
    "    - 5k\n",
    "    - 10k\n",
    "    - 15k\n",
    "    - 20k\n",
    "    - 25k\n",
    "    - 30k\n",
    "    - 35k\n",
    "    - 40k\n",
    "    \n",
    "\n",
    "One each of this DataSet will include this factors:\n",
    "    - tired level\n",
    "    - temperature\n",
    "    - humidity \n",
    "    - gender\n",
    "    - age\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First of all, add a label of which year is this results in the aim to diference the diferent runners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2015 = pd.read_csv(\"data_sets/marathon_results_2015.csv\")\n",
    "results_2016 = pd.read_csv(\"data_sets/marathon_results_2016.csv\")\n",
    "results_2017 = pd.read_csv(\"data_sets/marathon_results_2017.csv\")\n",
    "segments = ['5K', '10K', '15K', 'Half', '25K', '30K', '35K', '40K']\n",
    "results_2015['year'] = 2015\n",
    "results_2016['year'] = 2016\n",
    "results_2017['year'] = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Then delete the rows which have '-' instead of a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_times(data):\n",
    "    for segment in segments:\n",
    "        data = data[data[segment] != '-']\n",
    "    return data.copy()\n",
    "\n",
    "\n",
    "results_2015 = clean_times(results_2015)\n",
    "results_2016 = clean_times(results_2016)\n",
    "results_2017 = clean_times(results_2017)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Origin city elevation\n",
    "\n",
    "\n",
    "- Our aim here is to obtain the elevation of the diferent cities, because the best runners are this who born in a city with a hight elevation.\n",
    "\n",
    "- First of all we have to obtain the diferent cities on all years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_2015 = results_2015['City'].unique()\n",
    "cities_2016 = results_2016['City'].unique()\n",
    "cities_2017 = results_2017['City'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.7612525\n"
     ]
    }
   ],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent='myapplication')\n",
    "location = geolocator.geocode(cities_2015[1])\n",
    "print(location.raw['lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# script for returning elevation from lat, long, based on open elevation data\n",
    "# which in turn is based on SRTM\n",
    "def get_elevation(lat, long):\n",
    "    query = ('https://api.open-elevation.com/api/v1/lookup'\n",
    "             f'?locations=%s,%s' % ((lat, long )))\n",
    "    r = requests.get(query).json()  # json object, various ways you can extract value\n",
    "    # one approach is to use pandas json functionality:\n",
    "    elevation = pd.io.json.json_normalize(r, 'results')['elevation'].values[0]\n",
    "    return elevation\n",
    "\n",
    "get_elevation(\"42.361145\", \"-71.057083\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate information using open weather map\n",
    "\n",
    "https://darksky.net\n",
    "\n",
    "\n",
    "+ GET request: ```https://api.darksky.net/forecast/{API-Key}/{latitude}, {longitude}, {Unix time}```\n",
    "\n",
    "\n",
    "+ And our result will be a json with a lot of information, but we are only interested on this part : \n",
    "\n",
    "```\"currently\": {\n",
    "    \"time\": 1429520400,\n",
    "    \"summary\": \"Partly Cloudy\",\n",
    "    \"icon\": \"partly-cloudy-night\",\n",
    "    \"precipIntensity\": 0,\n",
    "    \"precipProbability\": 0,\n",
    "    \"temperature\": 41.45,\n",
    "    \"apparentTemperature\": 36.18,\n",
    "    \"dewPoint\": 38.25,\n",
    "    \"humidity\": 0.88,\n",
    "    \"pressure\": 1022.49,\n",
    "    \"windSpeed\": 8.34,\n",
    "    \"windGust\": 15.65,\n",
    "    \"windBearing\": 120,\n",
    "    \"cloudCover\": 0.36,\n",
    "    \"uvIndex\": 0,\n",
    "    \"visibility\": 10\n",
    "  },```\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "API_KEY = \"YOUR API KEY HERE\"\n",
    "latitude = \"42.361145\"\n",
    "longitude = \"-71.057083\"\n",
    "\n",
    "UNIX_2015 = 1429518650\n",
    "UNIX_2016 = 1429345850\n",
    "UNIX_2017 = 1492417850\n",
    "\n",
    "URI_2O15 = \"https://api.darksky.net/forecast/%s/%s, %s, %s\" % ((API_KEY, latitude ,longitude, UNIX_2015))\n",
    "URI_2016 = \"https://api.darksky.net/forecast/%s/%s, %s, %s\" % ((API_KEY, latitude ,longitude, UNIX_2016))\n",
    "URI_2017 = \"https://api.darksky.net/forecast/%s/%s, %s, %s\" % ((API_KEY, latitude ,longitude, UNIX_2017))\n",
    "\n",
    "weather_2015 = requests.get(URI_2O15).json()['currently']\n",
    "weather_2016 = requests.get(URI_2016).json()['currently']\n",
    "weather_2017 = requests.get(URI_2017).json()['currently']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add weather information to the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weather_info(results_year, weather_year):\n",
    "    results_year[\"humidity\"] = weather_year[\"humidity\"]\n",
    "    results_year[\"temperature\"] = weather_year[\"apparentTemperature\"]\n",
    "    \n",
    "add_weather_info(results_2015, weather_2015)\n",
    "add_weather_info(results_2016, weather_2016)\n",
    "add_weather_info(results_2017, weather_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split diferent segments\n",
    "\n",
    "- Each datafrem has to be splitted in eight Data Frames 5K, 10K, 15K, 20K, 25K , 30K, 35K, 40K. Also transform time to seconds and at a new parameter, current_time. This will be useful when we will want the heat and humidity at certain moment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sec(time_str):  \n",
    "    h, m, s = time_str.split(':')\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "\n",
    "def get_1km_partial(time, kms):\n",
    "    pass\n",
    "\n",
    "def segmentation(data_frame):\n",
    "    df_segments = {}\n",
    "    for segment in segments:\n",
    "        df_segment = pd.DataFrame()\n",
    "        df_segment['Name'] = data_frame['Name']\n",
    "        df_segment['time_arrived'] = list(map(get_sec, data_frame[segment].values))\n",
    "        df_segment['Current_time'] = \n",
    "        df_segment['temperature'] = df_segment['temperature']\n",
    "        df_segment['Tired_level'] = 0\n",
    "        df_segment['km_partial'] = 0\n",
    "        df_segment['Gender'] = data_frame['M/F']\n",
    "        df_segment['Age'] = data_frame['Age']\n",
    "        df_segment['City'] = data_frame['City']\n",
    "        df_segments[segment] = df_segment.copy()\n",
    "    return df_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_2015 = segmentation(results_2015)\n",
    "segments_2016 = segmentation(results_2016)\n",
    "segments_2017 = segmentation(results_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Merge all the same segments of diferent years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_segments(fragment_1, fragment_2, fragment_3):\n",
    "    all_segments = {}\n",
    "    for segment in segments:\n",
    "        all_segments[segment] = pd.concat([fragment_1[segment], fragment_2[segment], fragment_3[segment]])\n",
    "    return all_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_segments(segments_2015, segments_2016, segments_2017)['5K']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
