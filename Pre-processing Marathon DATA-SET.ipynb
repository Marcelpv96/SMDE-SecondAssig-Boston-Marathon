{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing boston marathon Data-set\n",
    "\n",
    "The aim of this is to process the three results available of boston marathon here:\n",
    "\n",
    "    - https://www.kaggle.com/rojour/boston-results\n",
    "    \n",
    "With the objective of split our information in this couple of segments:\n",
    "    - 5k\n",
    "    - 10k\n",
    "    - 15k\n",
    "    - 20k\n",
    "    - 25k\n",
    "    - 30k\n",
    "    - 35k\n",
    "    - 40k\n",
    "\n",
    "One each of this DataSet will include this factors:\n",
    "    - Relative temperature. Using wind speed, humidity, and other climate factors.\n",
    "    - Humidity. %Humidity, maybe this factor is redundant because it is included to calculate te relative temperature.\n",
    "    - Gender. Male/Female.\n",
    "    - Age. Using Years.\n",
    "    - Elevation of his/her birth city. Using meters.\n",
    "    \n",
    "    - Finally time in that he did the corresponding partial.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First of all, add a label of which year is this results in the aim to diference the diferent runners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2015 = pd.read_csv(\"data_sets/marathon_results_2015.csv\")\n",
    "results_2016 = pd.read_csv(\"data_sets/marathon_results_2016.csv\")\n",
    "results_2017 = pd.read_csv(\"data_sets/marathon_results_2017.csv\")\n",
    "segments = ['5K', '10K', '15K', 'Half', '25K', '30K', '35K', '40K']\n",
    "results_2015['year'] = 2015\n",
    "results_2016['year'] = 2016\n",
    "results_2017['year'] = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - Then delete the rows which have '-' instead of a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_times(data):\n",
    "    for segment in segments:\n",
    "        data = data[data[segment] != '-']\n",
    "    return data.copy()\n",
    "\n",
    "\n",
    "results_2015 = clean_times(results_2015)\n",
    "results_2016 = clean_times(results_2016)\n",
    "results_2017 = clean_times(results_2017)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Birth city elevation\n",
    "\n",
    "\n",
    "- Our aim here is to obtain the elevation of the diferent cities, because the best runners are this who born in a city with a hight elevation.\n",
    "\n",
    "- First of all we have to obtain the diferent cities on all years.\n",
    "\n",
    "- Then use from google maps api, geolocation (to obtain the latitude and longitude of a city name) and geocoding to obtain elevation.\n",
    "\n",
    "- Finally we will save as a csv the result, because we do not need to calculate this any time more, because it takes a lot of time and we only have only free 50k calls to the APIs and we do not want to waste its."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cities_df = pd.concat([results_2015, results_2016, results_2017])\n",
    "all_cities = all_cities_df['City'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "\n",
    "API_KEY=\"<HERE YOUR API KEY TO USE GOOGLE MAPS ELEVATION AND GEOCODING>\"\n",
    "\n",
    "\n",
    "def get_lat_lon(city):\n",
    "    query = \"https://maps.googleapis.com/maps/api/geocode/json?address= %s &key=%s\" %((city, API_KEY))\n",
    "    r = requests.get(query).json()\n",
    "    lat = r['results'][0]['geometry']['location']['lat']\n",
    "    lon = r['results'][0]['geometry']['location']['lng']\n",
    "    return lat, lon\n",
    "\n",
    "\n",
    "def get_elevation(lat, long):\n",
    "    query = 'https://maps.googleapis.com/maps/api/elevation/json?locations=%s, %s&key=%s' % ((lat, long, API_KEY))\n",
    "    r = requests.get(query).json()\n",
    "    elevation = pd.io.json.json_normalize(r, 'results')['elevation'].values[0]\n",
    "    return elevation\n",
    "\n",
    "\n",
    "def process_cities_elevations(all_cities):\n",
    "    todo = len(all_cities)\n",
    "    city_elevation = {\"cities\":[], \"elevations\":[]}\n",
    "    print(\" -> [STARTING] %d will be processed.\" %(len(all_cities)))\n",
    "    for city in all_cities:\n",
    "        try:\n",
    "            city = city[1]\n",
    "            lat, lon = get_lat_lon(city)\n",
    "            print(\"-> LAT : %s LON : %s obtained. \" % ((lat, lon)))\n",
    "            elevation = get_elevation(lat, lon)\n",
    "            print(\"-> processed %s elevation: %s, still %d.\" % ((city, elevation,todo)))\n",
    "        except:\n",
    "            elevation = -1\n",
    "        todo -= 1\n",
    "        city_elevation['cities'] += [city]\n",
    "        city_elevation['elevations'] += [elevation]\n",
    "    pd.DataFrame(city_elevation).to_csv(\"city_elevations.csv\" )\n",
    "    \n",
    "    \n",
    "process_cities_elevations(all_cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we have to add elevation to the three dataframes that we have results: 2015, 2016 and 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_elevation(cities_elevations, marathon_results):\n",
    "    elevations = []\n",
    "    for runner in range(0, marathon_results.shape[0]):\n",
    "        try:\n",
    "            runner_city = marathon_results.iloc[runner]['City']\n",
    "            elevation = cities_elevations[cities_elevations['cities'] == runner_city]['elevations'].iloc[0]\n",
    "            elevations.append(elevation)\n",
    "        except:\n",
    "            elevation = -1\n",
    "            elevations.append(elevation)\n",
    "    marathon_results['Elevation'] = elevations\n",
    "    return marathon_results[marathon_results['Elevation'] > -1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_elevations = pd.read_csv(\"city_elevations.csv\")\n",
    "results_2015 = add_elevation(cities_elevations, results_2015)\n",
    "results_2016 = add_elevation(cities_elevations, results_2016)\n",
    "results_2017 = add_elevation(cities_elevations, results_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add times he run the marathon \n",
    "\n",
    "- If he appears in all years, only two or only one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners_2015 = set(results_2015['Name'].unique())\n",
    "runners_2016 = set(results_2016['Name'].unique())\n",
    "runners_2017 = set(results_2017['Name'].unique())\n",
    "runners_years = [runners_2015, runners_2016, runners_2017]\n",
    "\n",
    "\n",
    "\n",
    "def times_runned(marathon_results, runners_years): \n",
    "    times_runned = []\n",
    "    for runner in range(0, marathon_results.shape[0]):\n",
    "        name = marathon_results.iloc[runner]['Name']\n",
    "        times = 0\n",
    "        for year_Results in runners_years:\n",
    "            if name in year_Results:\n",
    "                times += 1\n",
    "        times_runned += [times]\n",
    "    marathon_results['Times runned'] = times_runned\n",
    "    return marathon_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2015 = times_runned(results_2015, runners_2015)\n",
    "results_2016 = times_runned(results_2016, runners_2016)\n",
    "results_2017 = times_runned(results_2017, runners_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform gender to a not categorize attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transform M/F categorical to numerical, we will create two new features named M and F, where if M=0 and F=1 is a female or "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_mf(marathon_results):\n",
    "    M = []\n",
    "    F = []\n",
    "    for runner in range(0, marathon_results.shape[0]):\n",
    "        MF = marathon_results.iloc[runner]['M/F']\n",
    "        if MF == 'M':\n",
    "            M += [1]\n",
    "            F += [0]\n",
    "        if MF == 'F':\n",
    "            M += [0]\n",
    "            F += [1]\n",
    "    marathon_results['M'] = M\n",
    "    marathon_results['F'] = F\n",
    "    return marathon_results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2015 = transform_mf(results_2015)\n",
    "results_2016 = transform_mf(results_2016)\n",
    "results_2017 = transform_mf(results_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate information using open weather map\n",
    "\n",
    "https://darksky.net\n",
    "\n",
    "\n",
    "+ GET request: ```https://api.darksky.net/forecast/{API-Key}/{latitude}, {longitude}, {Unix time}```\n",
    "\n",
    "\n",
    "+ And our result will be a json with a lot of information, but we are only interested on this part : \n",
    "\n",
    "```\"currently\": {\n",
    "    \"time\": 1429520400,\n",
    "    \"summary\": \"Partly Cloudy\",\n",
    "    \"icon\": \"partly-cloudy-night\",\n",
    "    \"precipIntensity\": 0,\n",
    "    \"precipProbability\": 0,\n",
    "    \"temperature\": 41.45,\n",
    "    \"apparentTemperature\": 36.18,\n",
    "    \"dewPoint\": 38.25,\n",
    "    \"humidity\": 0.88,\n",
    "    \"pressure\": 1022.49,\n",
    "    \"windSpeed\": 8.34,\n",
    "    \"windGust\": 15.65,\n",
    "    \"windBearing\": 120,\n",
    "    \"cloudCover\": 0.36,\n",
    "    \"uvIndex\": 0,\n",
    "    \"visibility\": 10\n",
    "  },```\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "API_KEY = \"< HERE YOUR API KEY >\"\n",
    "latitude = \"42.361145\"\n",
    "longitude = \"-71.057083\"\n",
    "\n",
    "UNIX_2015 = 1429518650\n",
    "UNIX_2016 = 1429345850\n",
    "UNIX_2017 = 1492417850\n",
    "\n",
    "URI_2O15 = \"https://api.darksky.net/forecast/%s/%s, %s, %s\" % ((API_KEY, latitude ,longitude, UNIX_2015))\n",
    "URI_2016 = \"https://api.darksky.net/forecast/%s/%s, %s, %s\" % ((API_KEY, latitude ,longitude, UNIX_2016))\n",
    "URI_2017 = \"https://api.darksky.net/forecast/%s/%s, %s, %s\" % ((API_KEY, latitude ,longitude, UNIX_2017))\n",
    "\n",
    "weather_2015 = requests.get(URI_2O15).json()['currently']\n",
    "weather_2016 = requests.get(URI_2016).json()['currently']\n",
    "weather_2017 = requests.get(URI_2017).json()['currently']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add weather information to the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weather_info(marathon_results, weather_year):\n",
    "    marathon_results[\"humidity\"] = weather_year[\"humidity\"]\n",
    "    marathon_results[\"temperature\"] = weather_year[\"apparentTemperature\"]\n",
    "    return marathon_results\n",
    "\n",
    "\n",
    "results_2015 = add_weather_info(results_2015, weather_2015)\n",
    "results_2016 = add_weather_info(results_2016, weather_2016)\n",
    "results_2017 = add_weather_info(results_2017, weather_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform time to seconds\n",
    "\n",
    "- For the linear regression it will be necessary that the time be in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sec(time_str):  \n",
    "    try:\n",
    "        h, m, s = time_str.split(':')\n",
    "        return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "    except AttributeError:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def transform_time(marathon_results):\n",
    "    partials  = ['5K', '10K', '15K', '20K', 'Half', '25K', '30K', '35K', '40K','Official Time',]\n",
    "    marathon_results = marathon_results[marathon_results[partials] != '-']\n",
    "    for partial in partials:\n",
    "        marathon_results[partial] = list(map(get_sec ,marathon_results[partial]))              \n",
    "    return marathon_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2015 = transform_time(results_2015)\n",
    "results_2016 = transform_time(results_2016)\n",
    "results_2017 = transform_time(results_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_2015 = pd.read_csv(\"2015.csv\")\n",
    "results_2016 = pd.read_csv(\"2016.csv\")\n",
    "results_2017 = pd.read_csv(\"2017.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split diferent segments\n",
    "\n",
    "- Each datafrem has to be splitted in eight Data Frames 5K, 10K, 15K, 20K, 25K , 30K, 35K, 40K. Also transform time to seconds and at a new parameter, current_time. This will be useful when we will want the heat and humidity at certain moment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'Unnamed: 0.1',\n",
       " 'Bib',\n",
       " 'Name',\n",
       " 'Age',\n",
       " 'M/F',\n",
       " 'City',\n",
       " 'State',\n",
       " 'Country',\n",
       " 'Citizen',\n",
       " 'Unnamed: 9',\n",
       " '5K',\n",
       " '10K',\n",
       " '15K',\n",
       " '20K',\n",
       " 'Half',\n",
       " '25K',\n",
       " '30K',\n",
       " '35K',\n",
       " '40K',\n",
       " 'Pace',\n",
       " 'Proj Time',\n",
       " 'Official Time',\n",
       " 'Overall',\n",
       " 'Gender',\n",
       " 'Division',\n",
       " 'year',\n",
       " 'Elevation',\n",
       " 'Times runned',\n",
       " 'M',\n",
       " 'F',\n",
       " 'humidity',\n",
       " 'temperature']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(results_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sec(time_str): \n",
    "    print(time_s)\n",
    "    try:\n",
    "        h, m, s = time_str.split(':')\n",
    "        return int(h) * 3600 + int(m) * 60 + int(s)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "        \n",
    "\n",
    "def get_1km_partial(time, kms):\n",
    "    pass\n",
    "\n",
    "\n",
    "segments = ['5K', '10K', '15K', '20K', 'Half', '25K', '30K', '35K', '40K', 'Official Time']\n",
    "\n",
    "\n",
    "def generate_one_segment(marathon_results, segment):\n",
    "    segment_df = pd.DataFrame()\n",
    "    segment_df['Times runned'] = marathon_results['Times runned']\n",
    "    segment_df['Elevation'] = marathon_results['Elevation']\n",
    "    segment_df['temperature'] = marathon_results['temperature']\n",
    "    segment_df['M'] = marathon_results['M']\n",
    "    segment_df['F'] = marathon_results['F']\n",
    "    segment_df['Age'] = marathon_results['Age']\n",
    "    segment_df['humidity'] = marathon_results['humidity']\n",
    "    segment_df['arrival_time'] = marathon_results[segments[segment]].map(get_sec) \n",
    "    return segment_df\n",
    "\n",
    "def segmentation(all_marathon_results):\n",
    "    for segment in range(0, len(segments)):\n",
    "        segment_df = pd.concat([generate_one_segment(results, segment) for results in all_marathon_results])\n",
    "        segment_df.to_csv(\"%s.csv\" % segments[segment])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation([results_2015, results_2016, results_2017])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Merge all the same segments of diferent years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_segments(fragment_1, fragment_2, fragment_3):\n",
    "    all_segments = {}\n",
    "    for segment in segments:\n",
    "        all_segments[segment] = pd.concat([fragment_1[segment], fragment_2[segment], fragment_3[segment]])\n",
    "    return all_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_segments(segments_2015, segments_2016, segments_2017)['5K']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
